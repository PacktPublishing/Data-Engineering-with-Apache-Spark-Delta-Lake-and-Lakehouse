{"cells":[{"cell_type":"code","source":["from delta.tables import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType,array,ArrayType,DateType,TimestampType\nfrom pyspark.sql import functions as f\nfrom pyspark.sql.functions import udf\nimport hashlib\nimport datetime\nfrom datetime import timedelta, date"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"270aab33-7b21-4b8b-a47b-9191a2c4dd58"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["STORAGE_ACCOUNT=dbutils.widgets.get(\"STORAGE_ACCOUNT\")\nADLS_KEY=dbutils.widgets.get(\"ADLS_KEY\")\nBRONZE_LAYER_NAMESPACE=dbutils.widgets.get(\"BRONZE_LAYER_NAMESPACE\")\nSILVER_LAYER_NAMESPACE=dbutils.widgets.get(\"SILVER_LAYER_NAMESPACE\")\nSTORE_SALES_FOLDER=dbutils.widgets.get(\"STORE_SALES_FOLDER\")\nADLS_FOLDER=dbutils.widgets.get(\"ADLS_FOLDER\")\nTABLE_LIST=dbutils.widgets.get(\"TABLE_LIST\")\nCURRENCY_LIST=dbutils.widgets.get(\"CURRENCY_LIST\")\nCURRENCY_FOLDER=dbutils.widgets.get(\"CURRENCY_FOLDER\")\nGEOLOCATION_FOLDER=dbutils.widgets.get(\"GEOLOCATION_FOLDER\")\nLOGS_FOLDER=dbutils.widgets.get(\"LOGS_FOLDER\")\nECOMM_FOLDER=dbutils.widgets.get(\"ECOMM_FOLDER\")\n\nUPDATED=datetime.datetime.today().replace(second=0, microsecond=0)\nspark.conf.set(\"fs.azure.account.key.\"+STORAGE_ACCOUNT+\".blob.core.windows.net\", ADLS_KEY)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Parameters will be received from Azure Data Factory workflow","showTitle":true,"inputWidgets":{},"nuid":"6cf1224a-a398-4334-85e7-9d5c7eb98318"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["CUSTOMERS_SCHEMA =[\n    ('customer_id', IntegerType()),\n    ('customer_name', StringType()),\n    ('address', StringType()),\n    ('city', StringType()),\n    ('postalcode', StringType()),\n    ('country', StringType()),\n    ('phone', StringType()),\n    ('email', StringType()),\n    ('credit_card', StringType()),\n    ('updated_at', TimestampType())\n]\n\nORDERS_SCHEMA =[\n    ('order_number', IntegerType()),\n    ('customer_id', IntegerType()),\n    ('product_id', IntegerType()),\n    ('order_date', DateType()),\n    ('units', IntegerType()),\n    ('sale_price', FloatType()),\n    ('currency', StringType()),\n    ('order_mode', StringType()),\n    ('sale_price_usd', FloatType()),\n    ('updated_at', TimestampType())\n]\n\nPRODUCTS_SCHEMA =[\n    ('product_id', IntegerType()),\n    ('product_name', StringType()),\n    ('product_category', StringType()),\n    ('updated_at', TimestampType())\n]\n\nCURRENCY_SCHEMA =[\n    ('currency_value', FloatType()),\n    ('currency_name', StringType()),\n    ('updated_at', TimestampType())\n]\n\nGEOLOCATION_SCHEMA =[\n    ('ip1', StringType()),\n    ('ip2', StringType()),\n    ('country_code', StringType()),\n    ('country_name', StringType()),\n    ('updated_at', TimestampType())\n]\n\nLOGS_SCHEMA =[\n    ('time', StringType()),\n    ('remote_ip', StringType()),\n    ('request', StringType()),\n    ('response', StringType()),\n    ('agent', StringType()),\n    ('updated_at', TimestampType())\n]\n\nECOMM_SCHEMA =[\n    ('customer_name', StringType()),\n    ('address', StringType()),\n    ('city', StringType()),\n    ('country', StringType()),\n    ('currency', StringType()),\n    ('email', StringType()),\n    ('order_date', DateType()),\n    ('order_mode', StringType()),\n    ('order_number', IntegerType()),\n    ('phone', StringType()),\n    ('postalcode', StringType()),\n    ('product_name', StringType()),\n    ('sale_price', FloatType()),\n    ('sale_price_usd', FloatType()),\n    ('updated_at', TimestampType())\n]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Define Schemas for all files","showTitle":true,"inputWidgets":{},"nuid":"4196d554-b372-4dec-a814-0ca768daf4af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["def gen_blank_df(spark, schema_struct):\n    fields = [StructField(*field) for field in schema_struct]\n    schema = StructType(fields)\n    df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n    return df\n\ndef mask_value(column):\n  mask_value = hashlib.sha256(column.encode()).hexdigest()\n  return mask_value\n\ndef curate_email(email):\n  curated_value = email.lower()\n  return curated_value\n\ndef curate_country(country):\n  if (country == 'USA' or country == 'United States'):\n    curated_value = 'USA'\n  elif (country == 'UK' or country == 'United Kingdom'):\n    curated_value = 'UK'\n  elif (country == 'CAN' or country == 'Canada'):\n    curated_value = 'CAN'\n  elif (country == 'IND' or country == 'India'):\n    curated_value = 'IND'\n  else:\n    curated_value = country\n  return curated_value\n\ndef curate_sales_price(currency, currency_value, sales_price):\n  if (currency != 'USD'):\n    curated_value = float(sales_price)/float(currency_value)\n    return float(curated_value)\n  else:\n    return float(sales_price)\n\nmask_udf = udf(mask_value, StringType())\ncurate_email_udf = udf(curate_email, StringType())\ncurate_country_udf = udf(curate_country, StringType())\ncurate_sales_price_udf = udf(curate_sales_price, FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Define functions","showTitle":true,"inputWidgets":{},"nuid":"bff33e94-0734-41a7-83cc-bd43ea69fd59"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["currency_path=\"wasbs://\"+SILVER_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+CURRENCY_FOLDER\nfields = [StructField(*field) for field in CURRENCY_SCHEMA]\nschema_currency = StructType(fields)\ntry:\n  deltaTable = DeltaTable.forPath(spark, currency_path)\nexcept:\n  spark.sql(\"DROP TABLE IF EXISTS \"+ CURRENCY_FOLDER)\n  df_currency = gen_blank_df(spark, CURRENCY_SCHEMA)\n  df_currency.write.format(\"delta\").option(\"path\", currency_path).saveAsTable(CURRENCY_FOLDER)\n  deltaTable = DeltaTable.forPath(spark, currency_path)\n    \nfor currency in CURRENCY_LIST.split(\",\"):\n  bronze_currency_path=\"wasbs://\"+BRONZE_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+CURRENCY_FOLDER+\"/\"+currency+\"/\"+ADLS_FOLDER\n  #print(bronze_currency_path)\n\n  try:\n    df_currency_incremental = spark.read.csv(bronze_currency_path, schema=schema_currency )\n    df_currency_incremental=df_currency_incremental.withColumn('currency_name', f.lit(currency))\n    df_currency_incremental=df_currency_incremental.withColumn('updated_at', f.lit(UPDATED))\n\n    deltaTable.alias(\"currency\").merge(\n    df_currency_incremental.alias(\"currency_new\"),\n                    \"currency.currency_name = currency_new.currency_name\") \\\n                    .whenMatchedUpdate(set = {\"currency_value\":   \"currency_new.currency_value\", \t\\\n                                              \"updated_at\":       \"currency_new.updated_at\" } )     \\\n                    .whenNotMatchedInsert(values =                                                  \\\n                       {                                                    \n                                              \"currency_value\":   \"currency_new.currency_value\", \t\\\n                                              \"currency_name\":    \"currency_new.currency_name\",     \\\n                                              \"updated_at\":       \"currency_new.updated_at\"         \\\n                       }                                                                            \\\n                     ).execute()\n  except:\n    print(\"File for this date does not exist.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Curate Currency Data - standardize, mask and merge ","showTitle":true,"inputWidgets":{},"nuid":"0a469c9e-f544-46aa-9193-6a5c1b60dbbe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["for table in TABLE_LIST.split(\",\"):\n  \n  try:\n    table_path=\"wasbs://\"+SILVER_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+STORE_SALES_FOLDER+\"/\"+table\n    bronze_table_path=\"wasbs://\"+BRONZE_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+STORE_SALES_FOLDER+\"/\\[dbo\\].\\[\"+table+\"\\]/\"+ADLS_FOLDER\n    #print(bronze_table_path)\n    #print(table_path)\n  \n    if table==\"store_customers\":\n      partition_col=\"country\"\n      TABLE_SCHEMA=CUSTOMERS_SCHEMA\n    elif table==\"store_orders\":\n      partition_col=\"currency\"\n      TABLE_SCHEMA=ORDERS_SCHEMA\n    elif table==\"products\":\n      partition_col=\"product_category\"\n      TABLE_SCHEMA=PRODUCTS_SCHEMA\n    \n    \n    fields = [StructField(*field) for field in TABLE_SCHEMA]\n    schema_stores = StructType(fields)\n    try:\n      deltaTable = DeltaTable.forPath(spark, table_path)\n    except:\n      spark.sql(\"DROP TABLE IF EXISTS \"+ table)\n      df = gen_blank_df(spark,TABLE_SCHEMA)\n      df.write.format(\"delta\").option(\"path\", table_path).partitionBy(partition_col).saveAsTable(table)\n      deltaTable = DeltaTable.forPath(spark, table_path)\n\n    if table==\"store_customers\":\n      df_table_incremental = spark.read.csv(bronze_table_path, schema=schema_stores )\n      #display(df_table_incremental)\n      df_table_curated = df_table_incremental.withColumn('email_curated',curate_email_udf('email')).drop('email').withColumnRenamed('email_curated', 'email')\n\n      df_table_curated = df_table_curated.withColumn('country_curated',curate_country_udf('country')).drop('country').withColumnRenamed('country_curated', 'country')\n \n      df_table_curated = df_table_curated.withColumn('phone_masked',mask_udf('phone')).drop('phone').withColumnRenamed('phone_masked', 'phone')\n      df_table_curated = df_table_curated.withColumn('credit_card_masked',mask_udf('credit_card')).drop('credit_card').withColumnRenamed('credit_card_masked', 'credit_card')\n      df_table_curated = df_table_curated.withColumn('credit_card_masked',mask_udf('credit_card')).drop('credit_card').withColumnRenamed('credit_card_masked', 'credit_card')\n      df_table_curated = df_table_curated.withColumn('address_masked',mask_udf('address')).drop('address').withColumnRenamed('address_masked', 'address')\n      df_table_curated=df_table_curated.withColumn('updated_at', f.lit(UPDATED))\n\n      deltaTable.alias(\"store_customers\").merge(\n      df_table_curated.alias(\"store_customers_new\"),\n                      \"store_customers.email = store_customers_new.email\") \\\n                      .whenMatchedUpdate(set = {\"customer_id\": \t    \"store_customers_new.customer_id\", \t  \\\n                                                \"customer_name\":    \"store_customers_new.customer_name\",  \\\n                                                \"address\":          \"store_customers_new.address\",        \\\n                                                \"city\":             \"store_customers_new.city\",           \\\n                                                \"postalcode\":       \"store_customers_new.postalcode\",     \\\n                                                \"country\":          \"store_customers_new.country\",        \\\n                                                \"phone\":            \"store_customers_new.phone\",          \\\n                                                \"email\":            \"store_customers_new.email\",          \\\n                                                \"credit_card\":      \"store_customers_new.credit_card\",    \\\n                                                \"updated_at\":       \"store_customers_new.updated_at\" } )  \\\n                      .whenNotMatchedInsert(values =                                                      \\\n                         {                                                    \n                                                \"customer_id\": \t    \"store_customers_new.customer_id\", \t  \\\n                                                \"customer_name\":    \"store_customers_new.customer_name\",  \\\n                                                \"address\":          \"store_customers_new.address\",        \\\n                                                \"city\":             \"store_customers_new.city\",           \\\n                                                \"postalcode\":       \"store_customers_new.postalcode\",     \\\n                                                \"country\":          \"store_customers_new.country\",        \\\n                                                \"phone\":            \"store_customers_new.phone\",          \\\n                                                \"email\":            \"store_customers_new.email\",          \\\n                                                \"credit_card\":      \"store_customers_new.credit_card\",    \\\n                                                \"updated_at\":       \"store_customers_new.updated_at\"      \\\n                         }                                                                                \\\n                       ).execute()\n    elif table==\"store_orders\":\n      ORDERS_SCHEMA_1 =[('order_number', IntegerType()),('customer_id', IntegerType()),('product_id', IntegerType()),('order_date', StringType()),\n                        ('units', IntegerType()),('sale_price', FloatType()), ('currency', StringType()), \n                        ('order_mode', StringType()), ('sale_price_usd', FloatType()), ('updated_at', TimestampType())\n                       ]\n      fields = [StructField(*field) for field in ORDERS_SCHEMA_1]\n      schema_stores = StructType(fields)\n      df_table_incremental = spark.read.csv(bronze_table_path, schema=schema_stores )\n\n      df_currency=spark.sql('SELECT currency_name AS currency, currency_value from currency')\n      columns = ['currency', 'currency_value']\n      df_currency_usd = spark.createDataFrame([('USD','1')], columns)\n      df_currency_final=df_currency_usd.union(df_currency)\n     \n      df_table_curated = df_table_incremental.join(df_currency_final, on=['currency'], how=\"inner\")\n      df_table_curated = df_table_curated.withColumn('sale_price_usd',curate_sales_price_udf('currency', 'currency_value', 'sale_price'))\n      df_table_curated=df_table_curated.withColumn('updated_at', f.lit(UPDATED))\n      df_table_curated = df_table_curated.withColumn('order_date_new', to_date(df_table_curated.order_date, 'MM/dd/yyyy')).drop('order_date').withColumnRenamed('order_date_new', 'order_date')\n      df_table_curated = df_table_curated.drop('currency_value')\n      df_table_curated.show()\n\n      deltaTable.alias(\"store_orders\").merge(\n      df_table_curated.alias(\"store_orders_new\"),\n                      \"store_orders.order_number = store_orders_new.order_number\")                     \\\n                      .whenMatchedUpdate(set = {\"order_number\": \t\"store_orders_new.order_number\",   \\\n                                                \"customer_id\":      \"store_orders_new.customer_id\",    \\\n                                                \"product_id\":       \"store_orders_new.product_id\",     \\\n                                                \"order_date\":       \"store_orders_new.order_date\",     \\\n                                                \"units\":            \"store_orders_new.units\",          \\\n                                                \"sale_price\":       \"store_orders_new.sale_price\",     \\\n                                                \"sale_price_usd\":   \"store_orders_new.sale_price_usd\", \\\n                                                \"currency\":         \"store_orders_new.currency\",       \\\n                                                \"order_mode\":       \"store_orders_new.order_mode\",     \\\n                                                \"updated_at\":       \"store_orders_new.updated_at\" } )  \\\n                      .whenNotMatchedInsert(values =                                                   \\\n                         {                                                    \n                                                \"order_number\": \t\"store_orders_new.order_number\",   \\\n                                                \"customer_id\":      \"store_orders_new.customer_id\",    \\\n                                                \"product_id\":       \"store_orders_new.product_id\",     \\\n                                                \"order_date\":       \"store_orders_new.order_date\",     \\\n                                                \"units\":            \"store_orders_new.units\",          \\\n                                                \"sale_price\":       \"store_orders_new.sale_price\",     \\\n                                                \"sale_price_usd\":   \"store_orders_new.sale_price_usd\", \\\n                                                \"currency\":         \"store_orders_new.currency\",       \\\n                                                \"order_mode\":       \"store_orders_new.order_mode\",     \\\n                                                \"updated_at\":       \"store_orders_new.updated_at\"      \\\n                         }                                                                             \\\n                       ).execute()\n      deltaTable.delete(\"order_mode = 'DELETE'\")\n    elif table==\"products\":\n      df_table_incremental = spark.read.csv(bronze_table_path, schema=schema_stores )\n      df_table_curated=df_table_incremental.withColumn('updated_at', f.lit(UPDATED))\n\n      deltaTable.alias(\"products\").merge(\n      df_table_curated.alias(\"products_new\"),\n                      \"products.product_id = products_new.product_id\")                                \\\n                      .whenMatchedUpdate(set = {\"product_id\": \t    \"products_new.product_id\", \t      \\\n                                                \"product_name\":     \"products_new.product_name\",      \\\n                                                \"product_category\": \"products_new.product_category\",  \\\n                                                \"updated_at\":       \"products_new.updated_at\" } )     \\\n                      .whenNotMatchedInsert(values =                                                  \\\n                         {                                                    \n                                                \"product_id\": \t    \"products_new.product_id\", \t      \\\n                                                \"product_name\":     \"products_new.product_name\",      \\\n                                                \"product_category\": \"products_new.product_category\",  \\\n                                                \"updated_at\":       \"products_new.updated_at\"         \\\n                         }                                                                            \\\n                       ).execute()  \n\n  except:\n    print(\"File for this date does not exist.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Sales Data - standardize, mask and merge ","showTitle":true,"inputWidgets":{},"nuid":"eadcb415-56c4-4426-8241-a909653a5baf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["orphan_path=\"wasbs://\"+SILVER_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/exceptions/orphan_orders/\"+ADLS_FOLDER\ndf_store_orders_orphan=spark.sql(\"SELECT * FROM store_orders WHERE product_id NOT IN (SELECT product_id FROM products)\")\ndf_store_orders_orphan.write.parquet(orphan_path)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Find orphan store_orders","showTitle":true,"inputWidgets":{},"nuid":"ad34691f-5992-45df-a718-7ae998fa2801"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["geolocation_path=\"wasbs://\"+SILVER_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+GEOLOCATION_FOLDER\nfields = [StructField(*field) for field in GEOLOCATION_SCHEMA]\nschema_geolocation = StructType(fields)\ntry:\n  deltaTable = DeltaTable.forPath(spark, geolocation_path)\nexcept:\n  spark.sql(\"DROP TABLE IF EXISTS \"+ GEOLOCATION_FOLDER)\n  df_geolocation = gen_blank_df(spark, GEOLOCATION_SCHEMA)\n  df_geolocation.write.format(\"delta\").option(\"path\", geolocation_path).saveAsTable(GEOLOCATION_FOLDER)\n  deltaTable = DeltaTable.forPath(spark, geolocation_path)\n\n  bronze_geolocation_path=\"wasbs://\"+BRONZE_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+GEOLOCATION_FOLDER+\"/\"+ADLS_FOLDER\n\ntry:\n  df_geolocation_incremental = spark.read.csv(bronze_geolocation_path, schema=schema_geolocation )\n  df_geolocation_incremental=df_geolocation_incremental.withColumn('updated_at', f.lit(UPDATED))\n\n  deltaTable.alias(\"geolocation\").merge(\n    df_geolocation_incremental.alias(\"geolocation_new\"),\n                      \"geolocation.ip1 = geolocation_new.ip1\") \\\n                      .whenMatchedUpdate(set = {\"ip2\":              \"geolocation_new.ip2\", \t             \\\n                                                \"country_code\":     \"geolocation_new.country_code\",        \\\n                                                \"country_name\":     \"geolocation_new.country_name\",        \\\n                                                \"updated_at\":       \"geolocation_new.updated_at\" } )       \\\n                      .whenNotMatchedInsert(values =                                                       \\\n                         {                                                    \n                                                \"ip1\":              \"geolocation_new.ip1\", \t             \\\n                                                \"ip2\":              \"geolocation_new.ip2\", \t             \\\n                                                \"country_code\":     \"geolocation_new.country_code\",        \\\n                                                \"country_name\":     \"geolocation_new.country_name\",        \\\n                                                \"updated_at\":       \"geolocation_new.updated_at\"           \\\n                         }                                                                                 \\\n                       ).execute()\nexcept:\n  print(\"File for this date does not exist.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Curate Geolocation Data - standardize, mask and merge ","showTitle":true,"inputWidgets":{},"nuid":"f14b46be-3e48-4c1b-997d-6627b59facf4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["logs_path=\"wasbs://\"+SILVER_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+LOGS_FOLDER\nfields = [StructField(*field) for field in LOGS_SCHEMA]\nschema_logs = StructType(fields)\ntry:\n  deltaTable = DeltaTable.forPath(spark, logs_path)\nexcept:\n  spark.sql(\"DROP TABLE IF EXISTS \"+ LOGS_FOLDER)\n  df_logs = gen_blank_df(spark, LOGS_SCHEMA)\n  df_logs.write.format(\"delta\").option(\"path\", logs_path).saveAsTable(LOGS_FOLDER)\n  deltaTable = DeltaTable.forPath(spark, logs_path)\n  \nbronze_logs_path=\"wasbs://\"+BRONZE_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+LOGS_FOLDER+\"/\"+ADLS_FOLDER\n\ntry:\n  df_logs_incremental = spark.read.json(bronze_logs_path, schema=schema_logs )\n  df_logs_incremental = df_logs_incremental.withColumn('updated_at', f.lit(UPDATED))\n  df_logs_incremental = df_logs_incremental.withColumn('time_masked', from_unixtime(unix_timestamp('time', 'dd/MM         /yyy:HH:m:ss')).alias('time_masked')).drop('time').withColumnRenamed('time_masked', 'time')\n\n\n  deltaTable.alias(\"logs\").merge(\n  df_logs_incremental.alias(\"logs_new\"),\n                    \"logs.remote_ip = logs_new.remote_ip\")                                     \\\n                    .whenMatchedUpdate(set = {\"time\":              \"logs_new.time\", \t       \\\n                                              \"remote_ip\":         \"logs_new.remote_ip\",       \\\n                                              \"request\":           \"logs_new.request\",         \\\n                                              \"response\":          \"logs_new.response\",        \\\n                                              \"agent\":             \"logs_new.agent\",           \\\n                                              \"updated_at\":        \"logs_new.updated_at\" } )   \\\n                    .whenNotMatchedInsert(values =                                             \\\n                       {                                         \n                                              \"time\":              \"logs_new.time\", \t       \\\n                                              \"remote_ip\":         \"logs_new.remote_ip\",       \\\n                                              \"request\":           \"logs_new.request\",         \\\n                                              \"response\":          \"logs_new.response\",        \\\n                                              \"agent\":             \"logs_new.agent\",           \\\n                                              \"updated_at\":        \"logs_new.updated_at\"       \\\n                       }                                                                       \\\n                     ).execute()\nexcept:\n  print(\"File for this date does not exist.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Curate Logs Data - standardize, mask and merge ","showTitle":true,"inputWidgets":{},"nuid":"a1c594e4-f6e8-4624-a097-9a3b4c8e06fc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["ecomm_path=\"wasbs://\"+SILVER_LAYER_NAMESPACE+\"@\"+STORAGE_ACCOUNT+\".blob.core.windows.net/\"+ECOMM_FOLDER.split(\"/\")[0]\n\nfields = [StructField(*field) for field in ECOMM_SCHEMA]\nschema_ecomm = StructType(fields)\ntry:\n  deltaTable = DeltaTable.forPath(spark, ecomm_path)\nexcept:\n  spark.sql(\"DROP TABLE IF EXISTS \"+ ECOMM_FOLDER.split(\"/\")[0])\n  df_logs = gen_blank_df(spark, ECOMM_SCHEMA)\n  df_logs.printSchema()\n  df_logs.write.format(\"delta\").option(\"path\", ecomm_path).saveAsTable(ECOMM_FOLDER.split(\"/\")[0])\n  deltaTable = DeltaTable.forPath(spark, ecomm_path)\n\nbronze_ecomm_path=\"wasbs://bronze@traininglakehouse.blob.core.windows.net/\"+ECOMM_FOLDER\n\ntry:\n  df_ecomm=spark.read.format(\"avro\").load(bronze_ecomm_path)\n\n  df_ecomm_json = df_ecomm.select(df_ecomm.Body.cast(\"string\")).rdd.map(lambda x: x[0])\n  df_ecomm_data = spark.read.json(df_ecomm_json).select('data')\n  df_data_values = df_ecomm_data.select('data.customer_name', 'data.address', 'data.city', 'data.country', 'data.currency', 'data.email',\n                                        'data.order_date', 'data.order_mode', 'data.order_number', 'data.phone','data.postalcode', 'data.product_name', 'data.sale_price' )\n\n  df_data_values = df_data_values.withColumn('updated_at', f.lit(UPDATED))\n  df_data_values = df_data_values.withColumn('phone_masked',mask_udf('phone')).drop('phone').withColumnRenamed('phone_masked', 'phone')\n  df_data_values = df_data_values.withColumn('address_masked',mask_udf('address')).drop('address').withColumnRenamed('address_masked', 'address')\n  df_data_values = df_data_values.withColumn('order_date', from_unixtime(unix_timestamp('order_date', 'dd/MM/yyy')))\n  df_data_values = df_data_values.withColumn('country_curated',curate_country_udf('country')).drop('country').withColumnRenamed('country_curated', 'country')\n  \n  df_data_values = df_data_values.join(df_currency_final, on=['currency'], how=\"inner\")\n  df_data_values = df_data_values.withColumn('sale_price_usd',curate_sales_price_udf('currency', 'currency_value', 'sale_price'))\n\n  df_data_values = df_data_values.withColumn('order_date_new', to_date(df_data_values.order_date, 'yyyy-MM-dd HH:mm:ss')).drop('order_date').withColumnRenamed('order_date_new', 'order_date')\n  \n  #display(df_data_values)\n  deltaTable.alias(\"esalesns\").merge(\n  df_data_values.alias(\"esalesns_new\"),\n                    \"esalesns.email = esalesns_new.email\")                                          \\\n                    .whenMatchedUpdate(set = {\"customer_name\":    \"esalesns_new.customer_name\", \t\\\n                                              \"address\":          \"esalesns_new.address\",           \\\n                                              \"city\":             \"esalesns_new.city\",              \\\n                                              \"country\":          \"esalesns_new.country\",           \\\n                                              \"currency\":         \"esalesns_new.currency\",          \\\n                                              \"email\":            \"esalesns_new.email\",             \\\n                                              \"order_date\":       \"esalesns_new.order_date\",        \\\n                                              \"order_mode\":       \"esalesns_new.order_mode\",        \\\n                                              \"order_number\":     \"esalesns_new.order_number\",      \\\n                                              \"phone\":            \"esalesns_new.phone\",             \\\n                                              \"postalcode\":       \"esalesns_new.postalcode\",        \\\n                                              \"product_name\":     \"esalesns_new.product_name\",      \\\n                                              \"sale_price\":       \"esalesns_new.sale_price\",        \\\n                                              \"sale_price_usd\":   \"esalesns_new.sale_price_usd\",    \\\n                                              \"updated_at\":       \"esalesns_new.updated_at\" } )     \\\n                    .whenNotMatchedInsert(values =                                                  \\\n                       {                                         \n                                              \"customer_name\":    \"esalesns_new.customer_name\", \t\\\n                                              \"address\":          \"esalesns_new.address\",           \\\n                                              \"city\":             \"esalesns_new.city\",              \\\n                                              \"country\":          \"esalesns_new.country\",           \\\n                                              \"currency\":         \"esalesns_new.currency\",          \\\n                                              \"email\":            \"esalesns_new.email\",             \\\n                                              \"order_date\":       \"esalesns_new.order_date\",        \\\n                                              \"order_mode\":       \"esalesns_new.order_mode\",        \\\n                                              \"order_number\":     \"esalesns_new.order_number\",      \\\n                                              \"phone\":            \"esalesns_new.phone\",             \\\n                                              \"postalcode\":       \"esalesns_new.postalcode\",        \\\n                                              \"product_name\":     \"esalesns_new.product_name\",      \\\n                                              \"sale_price\":       \"esalesns_new.sale_price\",        \\\n                                              \"sale_price_usd\":   \"esalesns_new.sale_price_usd\",    \\\n                                              \"updated_at\":       \"esalesns_new.updated_at\"         \\\n                       }                                                                            \\\n                     ).execute()\nexcept:\n  print(\"File for this date does not exist.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Curate eCommerce Sales Data - standardize, mask and merge ","showTitle":true,"inputWidgets":{},"nuid":"18f8acea-b2ec-43db-9b6b-c82e1c9e5ad5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"electroniz_curation_notebook","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{"input":{"nuid":"5e183d17-2dac-4176-a32a-a642317f9baf","currentValue":"","widgetInfo":{"widgetType":"text","name":"input","defaultValue":"","label":"","options":{"widgetType":"text","validationRegex":null}}},"ADLS_KEY":{"nuid":"270c2350-c383-43e0-99ce-689151af7f86","currentValue":"","widgetInfo":{"widgetType":"text","name":"ADLS_KEY","defaultValue":"","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":313094028315802}},"nbformat":4,"nbformat_minor":0}
